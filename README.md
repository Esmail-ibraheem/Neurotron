# Neurotron

rebuild and implementation of early papers of ML such as CNN, RNN, ResNet, AlexNet, ViT, and Transformers (GPT, "attentions is all you need", Llama, Mistral)

in this rep, I will try to rebuild as many ML papers that were shown in the early days of AI development, my purpose of doing this is just for fun and learning, and also for educational purposes,
currently, I am thinking of building these papers: 
- CNN
- RNN
- ResNet
- AlexNet
- ViT
- DiT
- Transformer for translation
- GPT3
- Llama3.1
- Mistral
- nemotron
- megatron
- qwen2.5-coder
- etc...
- https://github.com/langchain-ai/rag-from-scratch
**The implementation will be as the name suggests from scratch, which means not just implementation in pure Pytorch but also with Cuda**
